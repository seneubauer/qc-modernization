{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622a1da9",
   "metadata": {},
   "source": [
    "### Perform Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89df432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "from random import sample\n",
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eir functions\n",
    "from eir_functions import clean_item_number, \\\n",
    "                          clean_drawing, \\\n",
    "                          clean_revision, \\\n",
    "                          clean_inspection_date, \\\n",
    "                          clean_inspector_operator, \\\n",
    "                          clean_disposition, \\\n",
    "                          clean_supplier, \\\n",
    "                          clean_receiver_number, \\\n",
    "                          clean_purchase_order, \\\n",
    "                          clean_job_order, \\\n",
    "                          clean_full_inspect_qty, \\\n",
    "                          clean_received_qty, \\\n",
    "                          clean_completed_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import confidential information\n",
    "from sys import path\n",
    "path.insert(0, \"..\")\n",
    "from config import eir_cleaned_destination_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd723c9a",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function prints out unique dataframe column values that contain certain values\n",
    "def print_unique_values(df: pd.DataFrame, find_vals: list, show_cols: list = []) -> None:\n",
    "\n",
    "    # define what columns are printed\n",
    "    column_names = []\n",
    "    if len(show_cols) > 0:\n",
    "        column_names = show_cols\n",
    "    else:\n",
    "        column_names = df.columns\n",
    "\n",
    "    # show all unique items in the column(s)\n",
    "    for column in column_names:\n",
    "        unique_list = [x for x in df[column].unique() if any(i in str(x) for i in find_vals)]\n",
    "        nan_count = df[column].isna().sum()\n",
    "        print(\"\")\n",
    "        print(f\"----- {column}: {len(unique_list):,.0f} (NaN: {nan_count:,.0f}) -----\")\n",
    "        for item in unique_list:\n",
    "            print(str(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef34dff",
   "metadata": {},
   "source": [
    "### Build Functional Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata function object\n",
    "meta_func_obj = {\n",
    "    \"item_number\": {\n",
    "        \"func\": clean_item_number,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [\" \"],\n",
    "            \"replace_delimitors\": [\"\\\\\", \"/\", \"(\", \")\"]\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"drawing\": {\n",
    "        \"func\": clean_drawing,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\" \", \".\"],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"revision\": {\n",
    "        \"func\": clean_revision,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\" \", \"-\", \"/\"],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"inspection_date\": {\n",
    "        \"func\": clean_inspection_date,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"datetime\"\n",
    "    },\n",
    "    \"inspector\": {\n",
    "        \"func\": clean_inspector_operator,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [\".\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\", \"<\", \">\"],\n",
    "            \"replace_delimitors\": [\"\\\\\", \"/\", \" \", \"-\", \",\"]\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"disposition\": {\n",
    "        \"func\": clean_disposition,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"supplier\": {\n",
    "        \"func\": clean_supplier,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"receiver_number\": {\n",
    "        \"func\": clean_receiver_number,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\"no\"],\n",
    "            \"remove_substrings\": [\" \"],\n",
    "            \"replace_delimitors\": [\"-\", \"/\", \",\"]\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"purchase_order\": {\n",
    "        \"func\": clean_purchase_order,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\"no\"],\n",
    "            \"remove_substrings\": [\" \"],\n",
    "            \"replace_delimitors\": [\"-\", \"/\", \",\"]\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"job_order\": {\n",
    "        \"func\": clean_job_order,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\".\", \"-\"],\n",
    "            \"remove_substrings\": [\" \"],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"operator\": {\n",
    "        \"func\": clean_inspector_operator,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [\".\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\", \"<\", \">\"],\n",
    "            \"replace_delimitors\": [\"\\\\\", \"/\", \" \", \"-\", \",\"]\n",
    "        },\n",
    "        \"target_data_type\": \"string\"\n",
    "    },\n",
    "    \"full_inspect_qty\": {\n",
    "        \"func\": clean_full_inspect_qty,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [],\n",
    "            \"remove_substrings\": [\" \"],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"float\"\n",
    "    },\n",
    "    \"received_qty\": {\n",
    "        \"func\": clean_received_qty,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\" \", \"/\"],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"float\"\n",
    "    },\n",
    "    \"completed_qty\": {\n",
    "        \"func\": clean_completed_qty,\n",
    "        \"args\": {\n",
    "            \"none_if_contains\": [\" \", \"/\", \"=\", \".\", \"-\"],\n",
    "            \"remove_substrings\": [],\n",
    "            \"replace_delimitors\": []\n",
    "        },\n",
    "        \"target_data_type\": \"float\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81c98d",
   "metadata": {},
   "source": [
    "### Read Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc367adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the two dataframes from csv\n",
    "raw_metadata_df = pd.read_csv(join(eir_cleaned_destination_csv, \"raw_metadata.csv\"), low_memory = False)\n",
    "raw_measurements_df = pd.read_csv(join(eir_cleaned_destination_csv, \"raw_measurements.csv\"), low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa3cb9",
   "metadata": {},
   "source": [
    "### Explore the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267c9ee",
   "metadata": {},
   "source": [
    "##### Show Unique Filtered Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters to view by\n",
    "find_vals = [\" \", \"{\", \"}\", \"[\", \"]\", \"(\", \")\", \"<\", \">\", \"\\\\\", \"/\", \",\", \"=\", \".\", \"|\", \"-\", \"_\"]\n",
    "\n",
    "# toggle these comments to experiment with what special characters 'clutter' a particular column\n",
    "# find_vals.remove(\" \")\n",
    "# find_vals.remove(\"{\")\n",
    "# find_vals.remove(\"}\")\n",
    "# find_vals.remove(\"[\")\n",
    "# find_vals.remove(\"]\")\n",
    "# find_vals.remove(\"(\")\n",
    "# find_vals.remove(\")\")\n",
    "# find_vals.remove(\"<\")\n",
    "# find_vals.remove(\">\")\n",
    "# find_vals.remove(\"\\\\\")\n",
    "# find_vals.remove(\"/\")\n",
    "# find_vals.remove(\",\")\n",
    "# find_vals.remove(\"=\")\n",
    "# find_vals.remove(\".\")\n",
    "# find_vals.remove(\"|\")\n",
    "# find_vals.remove(\"-\")\n",
    "# find_vals.remove(\"_\")\n",
    "\n",
    "# print the unique values that intersect with the find_vals list contents\n",
    "print_unique_values(raw_metadata_df, find_vals, show_cols = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fa9aa",
   "metadata": {},
   "source": [
    "## Clean the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec676eba",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd5771",
   "metadata": {},
   "source": [
    "This cell turns all unwanted values into `None` for easier handling down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e181e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a deep copy of the raw dataframe\n",
    "std_metadata_df = raw_metadata_df.copy(deep = True)\n",
    "\n",
    "# apply the metadata function object to standardize 'unwanted' values\n",
    "for k in meta_func_obj:\n",
    "\n",
    "    # reference the object children\n",
    "    my_func = meta_func_obj[k][\"func\"]\n",
    "    my_args = meta_func_obj[k][\"args\"]\n",
    "\n",
    "    if my_func is not None:\n",
    "        std_metadata_df.loc[:, k] = raw_metadata_df[k].apply(my_func, args = (my_args,))\n",
    "\n",
    "# characters to view by\n",
    "find_vals = [\" \", \"{\", \"}\", \"[\", \"]\", \"(\", \")\", \"<\", \">\", \"\\\\\", \"/\", \",\", \"=\", \".\", \"|\", \"-\"]\n",
    "\n",
    "# toggle these comments to experiment with what special characters 'clutter' a particular column\n",
    "# find_vals.remove(\" \")\n",
    "# find_vals.remove(\"{\")\n",
    "# find_vals.remove(\"}\")\n",
    "# find_vals.remove(\"[\")\n",
    "# find_vals.remove(\"]\")\n",
    "# find_vals.remove(\"(\")\n",
    "# find_vals.remove(\")\")\n",
    "# find_vals.remove(\"<\")\n",
    "# find_vals.remove(\">\")\n",
    "# find_vals.remove(\"\\\\\")\n",
    "# find_vals.remove(\"/\")\n",
    "# find_vals.remove(\",\")\n",
    "# find_vals.remove(\"=\")\n",
    "# find_vals.remove(\".\")\n",
    "# find_vals.remove(\"|\")\n",
    "# find_vals.remove(\"-\")\n",
    "\n",
    "# print the unique values that intersect with the find_vals list contents\n",
    "print_unique_values(std_metadata_df, find_vals, show_cols = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8cd4e",
   "metadata": {},
   "source": [
    "This cell removes `None` values from certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f53627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the row count before reduction\n",
    "rc_initial = std_metadata_df.shape[0]\n",
    "\n",
    "# create a reduced dataframe from the standardized dataframe\n",
    "red_metadata_df = std_metadata_df.loc[\n",
    "    (std_metadata_df[\"item_number\"].isna() == False) & \n",
    "    (std_metadata_df[\"drawing\"].isna() == False) & \n",
    "    (std_metadata_df[\"revision\"].isna() == False), :\n",
    "]\n",
    "\n",
    "# record the row count after reduction\n",
    "rc_reduced = red_metadata_df.shape[0]\n",
    "\n",
    "# show how many rows were lost to the reduction\n",
    "print(f\"Rows Lost: {rc_initial:,.0f} to {rc_reduced:,.0f} ({rc_reduced - rc_initial:,.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00722d81",
   "metadata": {},
   "source": [
    "This cell forces correct data types on the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deep copy of the reduced dataframe\n",
    "cln_metadata_df = red_metadata_df.copy(deep = True)\n",
    "\n",
    "# preview the current data types\n",
    "cln_metadata_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data types\n",
    "for k in meta_func_obj:\n",
    "    target = meta_func_obj[k][\"target_data_type\"]\n",
    "    if target == \"datetime\":\n",
    "        cln_metadata_df[k] = pd.to_datetime(cln_metadata_df[k], format = \"%Y-%m-%d\")\n",
    "    else:\n",
    "        cln_metadata_df = cln_metadata_df.astype({ k: target })\n",
    "\n",
    "# ensure the data types have changed\n",
    "cln_metadata_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db273153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "710397a8b05bc88245849d7f654cb110c8cd4ff861987adecb762b535430a3ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
